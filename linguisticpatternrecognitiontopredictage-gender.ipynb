{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3381,"sourceType":"datasetVersion","datasetId":1968}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lordshandilya/linguisticpatternrecognitiontopredictage-gender?scriptVersionId=170639260\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-06T12:00:14.331382Z","iopub.execute_input":"2024-04-06T12:00:14.332122Z","iopub.status.idle":"2024-04-06T12:00:15.400094Z","shell.execute_reply.started":"2024-04-06T12:00:14.332075Z","shell.execute_reply":"2024-04-06T12:00:15.398669Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/blog-authorship-corpus/blogtext.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/blog-authorship-corpus/blogtext.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:00:21.316983Z","iopub.execute_input":"2024-04-06T12:00:21.318577Z","iopub.status.idle":"2024-04-06T12:00:32.228481Z","shell.execute_reply.started":"2024-04-06T12:00:21.31852Z","shell.execute_reply":"2024-04-06T12:00:32.226024Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df =  df.drop(['id', 'topic', 'sign', 'date'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('/kaggle/working//blogtext.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom multiprocessing import Pool, cpu_count\n\n# Download NLTK stop words data\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet', '/usr/share/nltk_data')\n\nfrom nltk.corpus import wordnet\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:03:50.469453Z","iopub.execute_input":"2024-04-06T12:03:50.469925Z","iopub.status.idle":"2024-04-06T12:03:57.084403Z","shell.execute_reply.started":"2024-04-06T12:03:50.469893Z","shell.execute_reply":"2024-04-06T12:03:57.082909Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\nreplace /usr/share/nltk_data/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_special_char(text):\n    pattern = r'[^a-zA-Z0-9\\s]'\n    cleaned_text = re.sub(pattern, '', text)\n    return cleaned_text\ndef preprocessing(text):\n    \n    text = remove_special_char(text)\n    words = word_tokenize(text)\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer()\n    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n    filtered_text = ' '.join(filtered_words)\n    return filtered_text\n\ndef process_chunk(chunk):\n    chunk['text'] = chunk['text'].apply(preprocessing)\n    return chunk\n\ndef apply_preprocessing(File):\n    chunks = pd.read_csv(File, chunksize=1000)\n    \n    pool = Pool(cpu_count())\n    \n    processed_chunks = pool.map(process_chunk, chunks)\n    \n    pool.close()\n    pool.join()\n    \n    processed_df = pd.concat(processed_chunks)\n    \n    processed_df.to_csv(File, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:04:11.985995Z","iopub.execute_input":"2024-04-06T12:04:11.986509Z","iopub.status.idle":"2024-04-06T12:04:11.998215Z","shell.execute_reply.started":"2024-04-06T12:04:11.986468Z","shell.execute_reply":"2024-04-06T12:04:11.997096Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"apply_preprocessing('/kaggle/working//blogtext.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T12:04:19.853542Z","iopub.execute_input":"2024-04-06T12:04:19.854068Z","iopub.status.idle":"2024-04-06T12:16:48.808763Z","shell.execute_reply.started":"2024-04-06T12:04:19.854033Z","shell.execute_reply":"2024-04-06T12:16:48.807229Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working//blogtext.csv')\nprint(df.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_values = df.isna().sum()\n\nprint(\"The number of NaN in each column is :\")\nprint(nan_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Load the pre-trained BERT model\nbert_model = BertModel.from_pretrained('bert-base-uncased')\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze the BERT model layers\nfor param in bert_model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the dataset class\nclass BlogDataset(Dataset):\n    def __init__(self, df):\n        self.texts = df['text'].tolist()\n        self.genders = df['gender'].tolist()\n        self.ages = df['age'].tolist()\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        gender = self.genders[idx]\n        age = self.ages[idx]\n\n        input_ids = bert_tokenizer.encode(text, add_special_tokens=True, max_length=128, truncation=True)\n        attention_mask = [1] * len(input_ids)\n\n        return torch.tensor(input_ids), torch.tensor(attention_mask), torch.tensor(gender).float(), torch.tensor(age).float()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the model\nclass GenderAgeModel(nn.Module):\n    def __init__(self):\n        super(GenderAgeModel, self).__init__()\n        self.bert = bert_model\n        self.dropout = nn.Dropout(0.1)\n        self.gender_output = nn.Linear(768, 1)\n        self.age_output_1 = nn.Linear(768, 128)\n        self.age_output_2 = nn.Linear(128, 64)\n        self.age_output_3 = nn.Linear(64, 1)\n        self.sigmoid = nn.Sigmoid()\n        self.relu = nn.ReLU()\n\n    def forward(self, input_ids, attention_mask):\n        bert_output = self.bert(input_ids, attention_mask)[1]\n        bert_output = self.dropout(bert_output)\n        gender_output = self.sigmoid(self.gender_output(bert_output))\n        age_output_1 = self.relu(self.age_output_1(bert_output))\n        age_output_2 = self.relu(self.age_output_2(age_output_1))\n        age_output_3 = self.age_output_3(age_output_2)\n        return gender_output, age_output_3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ndf = pd.read_csv('/kaggle/working/blogtext.csv')\ndataset = BlogDataset(df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the DataLoader\nbatch_size = 32\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the model and define the loss functions and optimizer\nmodel = GenderAgeModel()\ngender_criterion = nn.BCELoss()\nage_criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(16):\n    for batch in train_loader:\n        input_ids, attention_mask, gender_labels, age_labels = batch\n\n        # Forward pass\n        gender_output, age_output = model(input_ids, attention_mask)\n\n        # Compute the losses\n        gender_loss = gender_criterion(gender_output, gender_labels)\n        age_loss = age_criterion(age_output, age_labels)\n\n        # Backpropagation and optimization\n        optimizer.zero_grad()\n        (gender_loss + age_loss).backward()\n        optimizer.step()\n\n    # Print the losses\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Gender Loss: {gender_loss.item()}, Age Loss: {age_loss.item()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}