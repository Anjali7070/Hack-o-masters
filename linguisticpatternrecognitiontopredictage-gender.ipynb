{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3381,"sourceType":"datasetVersion","datasetId":1968}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-06T10:56:53.204434Z","iopub.execute_input":"2024-04-06T10:56:53.204812Z","iopub.status.idle":"2024-04-06T10:56:54.470342Z","shell.execute_reply.started":"2024-04-06T10:56:53.204785Z","shell.execute_reply":"2024-04-06T10:56:54.469383Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/blog-authorship-corpus/blogtext.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/blog-authorship-corpus/blogtext.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:58:00.707441Z","iopub.execute_input":"2024-04-06T10:58:00.707829Z","iopub.status.idle":"2024-04-06T10:58:11.286752Z","shell.execute_reply.started":"2024-04-06T10:58:00.707799Z","shell.execute_reply":"2024-04-06T10:58:11.285424Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df =  df.drop(['id', 'topic', 'sign', 'date'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:58:18.762944Z","iopub.execute_input":"2024-04-06T10:58:18.763607Z","iopub.status.idle":"2024-04-06T10:58:18.824893Z","shell.execute_reply.started":"2024-04-06T10:58:18.763568Z","shell.execute_reply":"2024-04-06T10:58:18.823765Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:58:23.263245Z","iopub.execute_input":"2024-04-06T10:58:23.264226Z","iopub.status.idle":"2024-04-06T10:58:23.274519Z","shell.execute_reply.started":"2024-04-06T10:58:23.264166Z","shell.execute_reply":"2024-04-06T10:58:23.273222Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"  gender  age                                               text\n0   male   15             Info has been found (+/- 100 pages,...\n1   male   15             These are the team members:   Drewe...\n2   male   15             In het kader van kernfusie op aarde...\n3   male   15                   testing!!!  testing!!!          \n4   male   33               Thanks to Yahoo!'s Toolbar I can ...\n","output_type":"stream"}]},{"cell_type":"code","source":"df.to_csv('/kaggle/working//blogtext.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:58:41.911491Z","iopub.execute_input":"2024-04-06T10:58:41.911863Z","iopub.status.idle":"2024-04-06T10:59:19.440798Z","shell.execute_reply.started":"2024-04-06T10:58:41.911835Z","shell.execute_reply":"2024-04-06T10:59:19.439475Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom multiprocessing import Pool, cpu_count\n\n# Download NLTK stop words data\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet', '/usr/share/nltk_data')\n\nfrom nltk.corpus import wordnet\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:59:37.638350Z","iopub.execute_input":"2024-04-06T10:59:37.638772Z","iopub.status.idle":"2024-04-06T10:59:41.766105Z","shell.execute_reply.started":"2024-04-06T10:59:37.638739Z","shell.execute_reply":"2024-04-06T10:59:41.764760Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_special_char(text):\n    pattern = r'[^a-zA-Z0-9\\s]'\n    cleaned_text = re.sub(pattern, '', text)\n    return cleaned_text\ndef preprocessing(text):\n    \n    text = remove_special_char(text)\n    words = word_tokenize(text)\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer()\n    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n    filtered_text = ' '.join(filtered_words)\n    return filtered_text\n\ndef process_chunk(chunk):\n    chunk['text'] = chunk['text'].apply(preprocessing)\n    return chunk\n\ndef apply_preprocessing(File):\n    chunks = pd.read_csv(File, chunksize=1000)\n    \n    pool = Pool(cpu_count())\n    \n    processed_chunks = pool.map(process_chunk, chunks)\n    \n    pool.close()\n    pool.join()\n    \n    processed_df = pd.concat(processed_chunks)\n    \n    processed_df.to_csv(File, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:59:47.004652Z","iopub.execute_input":"2024-04-06T10:59:47.005060Z","iopub.status.idle":"2024-04-06T10:59:47.016025Z","shell.execute_reply.started":"2024-04-06T10:59:47.005027Z","shell.execute_reply":"2024-04-06T10:59:47.014815Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"apply_preprocessing('/kaggle/working//blogtext.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-06T10:59:54.289835Z","iopub.execute_input":"2024-04-06T10:59:54.290272Z","iopub.status.idle":"2024-04-06T11:12:15.365962Z","shell.execute_reply.started":"2024-04-06T10:59:54.290241Z","shell.execute_reply":"2024-04-06T11:12:15.363239Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working//blogtext.csv')\nprint(df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:12:34.902083Z","iopub.execute_input":"2024-04-06T11:12:34.902606Z","iopub.status.idle":"2024-04-06T11:12:41.577510Z","shell.execute_reply.started":"2024-04-06T11:12:34.902568Z","shell.execute_reply":"2024-04-06T11:12:41.576481Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"  gender  age                                               text\n0   male   15  info found 100 page 45 mb pdf file wait untill...\n1   male   15  team member drewes van der laag urllink mail r...\n2   male   15  het kader van kernfusie op aarde maak je eigen...\n3   male   15                                    testing testing\n4   male   33  thanks yahoo toolbar capture url popupswhich m...\n","output_type":"stream"}]},{"cell_type":"code","source":"nan_values = df.isna().sum()\n\nprint(\"The number of NaN in each column is :\")\nprint(nan_values)","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:14:08.269289Z","iopub.execute_input":"2024-04-06T11:14:08.269729Z","iopub.status.idle":"2024-04-06T11:14:08.456843Z","shell.execute_reply.started":"2024-04-06T11:14:08.269698Z","shell.execute_reply":"2024-04-06T11:14:08.455513Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"The number of NaN in each column is :\ngender    0\nage       0\ntext      0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:14:14.756238Z","iopub.execute_input":"2024-04-06T11:14:14.756629Z","iopub.status.idle":"2024-04-06T11:14:14.971914Z","shell.execute_reply.started":"2024-04-06T11:14:14.756600Z","shell.execute_reply":"2024-04-06T11:14:14.971012Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:15:11.264950Z","iopub.execute_input":"2024-04-06T11:15:11.265410Z","iopub.status.idle":"2024-04-06T11:15:20.424982Z","shell.execute_reply.started":"2024-04-06T11:15:11.265377Z","shell.execute_reply":"2024-04-06T11:15:20.423824Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n# Load the pre-trained BERT model\nbert_model = BertModel.from_pretrained('bert-base-uncased')\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:15:27.691365Z","iopub.execute_input":"2024-04-06T11:15:27.692002Z","iopub.status.idle":"2024-04-06T11:15:31.887742Z","shell.execute_reply.started":"2024-04-06T11:15:27.691968Z","shell.execute_reply":"2024-04-06T11:15:31.886486Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef880b85d6c43e6a935de35f17fbf27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35d9ec4962d54473b77a55facc1dce6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16d7c0ac04a4dc2ae8ab945b5c1dcea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45e26f80ba604f6092fe5e374a49edf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"784dacdc878344eb985a24b583ea00e8"}},"metadata":{}}]},{"cell_type":"code","source":"# Freeze the BERT model layers\nfor param in bert_model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:16:02.868466Z","iopub.execute_input":"2024-04-06T11:16:02.868904Z","iopub.status.idle":"2024-04-06T11:16:02.876618Z","shell.execute_reply.started":"2024-04-06T11:16:02.868874Z","shell.execute_reply":"2024-04-06T11:16:02.875534Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Create the dataset class\nclass BlogDataset(Dataset):\n    def __init__(self, df):\n        self.texts = df['text'].tolist()\n        self.genders = df['gender'].tolist()\n        self.ages = df['age'].tolist()\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        gender = self.genders[idx]\n        age = self.ages[idx]\n\n        input_ids = bert_tokenizer.encode(text, add_special_tokens=True, max_length=128, truncation=True)\n        attention_mask = [1] * len(input_ids)\n\n        return torch.tensor(input_ids), torch.tensor(attention_mask), torch.tensor(gender).float(), torch.tensor(age).float()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:16:17.846612Z","iopub.execute_input":"2024-04-06T11:16:17.847061Z","iopub.status.idle":"2024-04-06T11:16:17.858133Z","shell.execute_reply.started":"2024-04-06T11:16:17.847028Z","shell.execute_reply":"2024-04-06T11:16:17.856811Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Create the model\nclass GenderAgeModel(nn.Module):\n    def __init__(self):\n        super(GenderAgeModel, self).__init__()\n        self.bert = bert_model\n        self.dropout = nn.Dropout(0.1)\n        self.gender_output = nn.Linear(768, 1)\n        self.age_output_1 = nn.Linear(768, 128)\n        self.age_output_2 = nn.Linear(128, 64)\n        self.age_output_3 = nn.Linear(64, 1)\n        self.sigmoid = nn.Sigmoid()\n        self.relu = nn.ReLU()\n\n    def forward(self, input_ids, attention_mask):\n        bert_output = self.bert(input_ids, attention_mask)[1]\n        bert_output = self.dropout(bert_output)\n        gender_output = self.sigmoid(self.gender_output(bert_output))\n        age_output_1 = self.relu(self.age_output_1(bert_output))\n        age_output_2 = self.relu(self.age_output_2(age_output_1))\n        age_output_3 = self.age_output_3(age_output_2)\n        return gender_output, age_output_3","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:16:21.567575Z","iopub.execute_input":"2024-04-06T11:16:21.567980Z","iopub.status.idle":"2024-04-06T11:16:21.579461Z","shell.execute_reply.started":"2024-04-06T11:16:21.567950Z","shell.execute_reply":"2024-04-06T11:16:21.578106Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Load the data\ndf = pd.read_csv('/kaggle/working/blogtext.csv')\ndataset = BlogDataset(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:16:26.863497Z","iopub.execute_input":"2024-04-06T11:16:26.863935Z","iopub.status.idle":"2024-04-06T11:16:33.571264Z","shell.execute_reply.started":"2024-04-06T11:16:26.863904Z","shell.execute_reply":"2024-04-06T11:16:33.569800Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create the DataLoader\nbatch_size = 32\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:16:57.546678Z","iopub.execute_input":"2024-04-06T11:16:57.547091Z","iopub.status.idle":"2024-04-06T11:16:57.553317Z","shell.execute_reply.started":"2024-04-06T11:16:57.547062Z","shell.execute_reply":"2024-04-06T11:16:57.552032Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Initialize the model and define the loss functions and optimizer\nmodel = GenderAgeModel()\ngender_criterion = nn.BCELoss()\nage_criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:17:26.602342Z","iopub.execute_input":"2024-04-06T11:17:26.602760Z","iopub.status.idle":"2024-04-06T11:17:26.619203Z","shell.execute_reply.started":"2024-04-06T11:17:26.602730Z","shell.execute_reply":"2024-04-06T11:17:26.617921Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(16):\n    for batch in train_loader:\n        input_ids, attention_mask, gender_labels, age_labels = batch\n\n        # Forward pass\n        gender_output, age_output = model(input_ids, attention_mask)\n\n        # Compute the losses\n        gender_loss = gender_criterion(gender_output, gender_labels)\n        age_loss = age_criterion(age_output, age_labels)\n\n        # Backpropagation and optimization\n        optimizer.zero_grad()\n        (gender_loss + age_loss).backward()\n        optimizer.step()\n\n    # Print the losses\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Gender Loss: {gender_loss.item()}, Age Loss: {age_loss.item()}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-06T11:18:23.605335Z","iopub.execute_input":"2024-04-06T11:18:23.605818Z","iopub.status.idle":"2024-04-06T11:18:24.013229Z","shell.execute_reply.started":"2024-04-06T11:18:23.605785Z","shell.execute_reply":"2024-04-06T11:18:24.011387Z"},"trusted":true},"execution_count":26,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      4\u001b[0m         input_ids, attention_mask, gender_labels, age_labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[20], line 19\u001b[0m, in \u001b[0;36mBlogDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m bert_tokenizer\u001b[38;5;241m.\u001b[39mencode(text, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_ids)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(input_ids), torch\u001b[38;5;241m.\u001b[39mtensor(attention_mask), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgender\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat(), torch\u001b[38;5;241m.\u001b[39mtensor(age)\u001b[38;5;241m.\u001b[39mfloat()\n","\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"],"ename":"TypeError","evalue":"new(): invalid data type 'str'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}