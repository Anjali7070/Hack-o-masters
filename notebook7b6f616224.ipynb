{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3381,"sourceType":"datasetVersion","datasetId":1968}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T00:29:38.341487Z","iopub.execute_input":"2024-04-07T00:29:38.341844Z","iopub.status.idle":"2024-04-07T00:29:38.357929Z","shell.execute_reply.started":"2024-04-07T00:29:38.341821Z","shell.execute_reply":"2024-04-07T00:29:38.356958Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/blog-authorship-corpus/blogtext.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/blog-authorship-corpus/blogtext.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:29:44.298526Z","iopub.execute_input":"2024-04-07T00:29:44.299212Z","iopub.status.idle":"2024-04-07T00:30:00.133485Z","shell.execute_reply.started":"2024-04-07T00:29:44.299182Z","shell.execute_reply":"2024-04-07T00:30:00.132686Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df =  df.drop(['id', 'topic', 'sign', 'date'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:30:03.792685Z","iopub.execute_input":"2024-04-07T00:30:03.793058Z","iopub.status.idle":"2024-04-07T00:30:03.846470Z","shell.execute_reply.started":"2024-04-07T00:30:03.793031Z","shell.execute_reply":"2024-04-07T00:30:03.845742Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.to_csv('/kaggle/working//blogtext.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:30:05.984162Z","iopub.execute_input":"2024-04-07T00:30:05.984502Z","iopub.status.idle":"2024-04-07T00:30:37.835212Z","shell.execute_reply.started":"2024-04-07T00:30:05.984474Z","shell.execute_reply":"2024-04-07T00:30:37.834365Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import re\nimport nltk\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom multiprocessing import Pool, cpu_count\n\n# Download NLTK stop words data\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet', '/usr/share/nltk_data')\n\nfrom nltk.corpus import wordnet\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:30:44.085740Z","iopub.execute_input":"2024-04-07T00:30:44.086123Z","iopub.status.idle":"2024-04-07T00:30:47.310133Z","shell.execute_reply.started":"2024-04-07T00:30:44.086096Z","shell.execute_reply":"2024-04-07T00:30:47.308851Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_special_char(text):\n    pattern = r'[^a-zA-Z0-9\\s]'\n    cleaned_text = re.sub(pattern, '', text)\n    return cleaned_text\ndef preprocessing(text):\n\n    text = remove_special_char(text)\n    words = word_tokenize(text)\n    stop_words = set(stopwords.words('english'))\n    lemmatizer = WordNetLemmatizer()\n    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words]\n    filtered_text = ' '.join(filtered_words)\n    return filtered_text\n\ndef process_chunk(chunk):\n    chunk['text'] = chunk['text'].apply(preprocessing)\n    return chunk\n\ndef apply_preprocessing(File):\n    chunks = pd.read_csv(File, chunksize=1000)\n\n    pool = Pool(cpu_count())\n\n    processed_chunks = pool.map(process_chunk, chunks)\n\n    pool.close()\n    pool.join()\n\n    processed_df = pd.concat(processed_chunks)\n\n    processed_df.to_csv(File, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:30:53.026468Z","iopub.execute_input":"2024-04-07T00:30:53.027184Z","iopub.status.idle":"2024-04-07T00:30:53.037521Z","shell.execute_reply.started":"2024-04-07T00:30:53.027151Z","shell.execute_reply":"2024-04-07T00:30:53.036453Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"apply_preprocessing('/kaggle/working//blogtext.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:30:58.259417Z","iopub.execute_input":"2024-04-07T00:30:58.260068Z","iopub.status.idle":"2024-04-07T00:41:00.944449Z","shell.execute_reply.started":"2024-04-07T00:30:58.260029Z","shell.execute_reply":"2024-04-07T00:41:00.943336Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:41:25.093141Z","iopub.execute_input":"2024-04-07T00:41:25.093532Z","iopub.status.idle":"2024-04-07T00:41:25.526941Z","shell.execute_reply.started":"2024-04-07T00:41:25.093503Z","shell.execute_reply":"2024-04-07T00:41:25.526040Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:41:34.496501Z","iopub.execute_input":"2024-04-07T00:41:34.496859Z","iopub.status.idle":"2024-04-07T00:41:42.019301Z","shell.execute_reply.started":"2024-04-07T00:41:34.496830Z","shell.execute_reply":"2024-04-07T00:41:42.018483Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n# Load the pre-trained BERT model\nbert_model = BertModel.from_pretrained('bert-base-uncased')\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:41:43.968632Z","iopub.execute_input":"2024-04-07T00:41:43.969603Z","iopub.status.idle":"2024-04-07T00:41:47.478699Z","shell.execute_reply.started":"2024-04-07T00:41:43.969570Z","shell.execute_reply":"2024-04-07T00:41:47.477969Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b16e0b106941c1b51cdf71751171dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d73b9335909d411a8c39c3b7a7bf2295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90f9e5b687a4df78ebbe9c99563a4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a066a8edc1504aef8dc004e04a9c83ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f31d551989894a85bfaeffde5d50ee5b"}},"metadata":{}}]},{"cell_type":"code","source":"# Freeze the BERT model layers\nfor param in bert_model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:41:54.729304Z","iopub.execute_input":"2024-04-07T00:41:54.729666Z","iopub.status.idle":"2024-04-07T00:41:54.735555Z","shell.execute_reply.started":"2024-04-07T00:41:54.729640Z","shell.execute_reply":"2024-04-07T00:41:54.734347Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Create the dataset class\nclass BlogDataset(Dataset):\n    def __init__(self, df):\n        self.texts = df['text'].tolist()\n        self.genders = [0 if g == 'male' else 1 for g in df['gender'].tolist()]\n        self.ages = df['age'].tolist()\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        gender = self.genders[idx]\n        age = self.ages[idx]\n\n        input_ids = bert_tokenizer.encode(text, add_special_tokens=True, max_length=128, truncation=True)\n        attention_mask = [1] * len(input_ids)\n\n        return input_ids, attention_mask, gender, age","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:41:56.526844Z","iopub.execute_input":"2024-04-07T00:41:56.527699Z","iopub.status.idle":"2024-04-07T00:41:56.534905Z","shell.execute_reply.started":"2024-04-07T00:41:56.527664Z","shell.execute_reply":"2024-04-07T00:41:56.533798Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:42:03.093105Z","iopub.execute_input":"2024-04-07T00:42:03.093782Z","iopub.status.idle":"2024-04-07T00:42:03.097959Z","shell.execute_reply.started":"2024-04-07T00:42:03.093749Z","shell.execute_reply":"2024-04-07T00:42:03.097029Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\ndef collate_fn(batch):\n    input_ids, attention_mask, genders, ages = zip(*batch)\n    input_ids = pad_sequence([torch.tensor(x) for x in input_ids], batch_first=True, padding_value=0)\n    attention_mask = pad_sequence([torch.tensor(x) for x in attention_mask], batch_first=True, padding_value=0)\n    genders = torch.tensor([x for x in genders]).float()\n    ages = torch.tensor([x for x in ages]).float()\n    return input_ids, attention_mask, genders, ages","metadata":{"execution":{"iopub.status.busy":"2024-04-07T00:42:08.911709Z","iopub.execute_input":"2024-04-07T00:42:08.912463Z","iopub.status.idle":"2024-04-07T00:42:08.918893Z","shell.execute_reply.started":"2024-04-07T00:42:08.912428Z","shell.execute_reply":"2024-04-07T00:42:08.917904Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Create the model\nclass GenderAgeModel(nn.Module):\n    def __init__(self):\n        super(GenderAgeModel, self).__init__()\n        self.bert = bert_model\n        self.dropout = nn.Dropout(0.1)\n        self.gender_output = nn.Linear(768, 1)\n        self.age_output_1 = nn.Linear(768, 128)\n        self.age_output_2 = nn.Linear(128, 64)\n        self.age_output_3 = nn.Linear(64, 1)  # Linear output layer\n        self.sigmoid = nn.Sigmoid()\n        self.relu = nn.ReLU()\n\n    def forward(self, input_ids, attention_mask):\n        bert_output = self.bert(input_ids, attention_mask)[1]\n        bert_output = self.dropout(bert_output)\n        gender_output = self.sigmoid(self.gender_output(bert_output))\n        age_output_1 = self.relu(self.age_output_1(bert_output))\n        age_output_2 = self.relu(self.age_output_2(age_output_1))\n        age_output_3 = self.age_output_3(age_output_2)  # No activation\n        return gender_output, age_output_3","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:30:38.863288Z","iopub.execute_input":"2024-04-07T03:30:38.863665Z","iopub.status.idle":"2024-04-07T03:30:38.873046Z","shell.execute_reply.started":"2024-04-07T03:30:38.863636Z","shell.execute_reply":"2024-04-07T03:30:38.872052Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:30:43.051548Z","iopub.execute_input":"2024-04-07T03:30:43.051905Z","iopub.status.idle":"2024-04-07T03:30:43.056323Z","shell.execute_reply.started":"2024-04-07T03:30:43.051880Z","shell.execute_reply":"2024-04-07T03:30:43.055219Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"from accelerate import Accelerator\n\naccelerator = Accelerator()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:30:44.102721Z","iopub.execute_input":"2024-04-07T03:30:44.103096Z","iopub.status.idle":"2024-04-07T03:30:44.108725Z","shell.execute_reply.started":"2024-04-07T03:30:44.103068Z","shell.execute_reply":"2024-04-07T03:30:44.107749Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"device = accelerator.device\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:30:45.162803Z","iopub.execute_input":"2024-04-07T03:30:45.163525Z","iopub.status.idle":"2024-04-07T03:30:45.167940Z","shell.execute_reply.started":"2024-04-07T03:30:45.163494Z","shell.execute_reply":"2024-04-07T03:30:45.166790Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/blogtext.csv')\ndf =df.dropna()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:30:49.378079Z","iopub.execute_input":"2024-04-07T03:30:49.378440Z","iopub.status.idle":"2024-04-07T03:30:54.642661Z","shell.execute_reply.started":"2024-04-07T03:30:49.378414Z","shell.execute_reply":"2024-04-07T03:30:54.641783Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Create the DataLoader\nbatch_size = 1024\n\n# Split the data into training and test sets\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Create the training dataset and data loader\ntrain_dataset = BlogDataset(train_df)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n\n# Create the test dataset and data loader\ntest_dataset = BlogDataset(test_df)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:30:59.294395Z","iopub.execute_input":"2024-04-07T03:30:59.295155Z","iopub.status.idle":"2024-04-07T03:30:59.591859Z","shell.execute_reply.started":"2024-04-07T03:30:59.295116Z","shell.execute_reply":"2024-04-07T03:30:59.591012Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Initialize the model and define the loss functions and optimizer\nmodel = GenderAgeModel()\ngender_criterion = nn.BCELoss()\nage_criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:31:10.317233Z","iopub.execute_input":"2024-04-07T03:31:10.318157Z","iopub.status.idle":"2024-04-07T03:31:10.334063Z","shell.execute_reply.started":"2024-04-07T03:31:10.318123Z","shell.execute_reply":"2024-04-07T03:31:10.333336Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:31:11.678933Z","iopub.execute_input":"2024-04-07T03:31:11.679330Z","iopub.status.idle":"2024-04-07T03:31:11.683948Z","shell.execute_reply.started":"2024-04-07T03:31:11.679300Z","shell.execute_reply":"2024-04-07T03:31:11.682627Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:31:24.440607Z","iopub.execute_input":"2024-04-07T03:31:24.440993Z","iopub.status.idle":"2024-04-07T03:31:24.446346Z","shell.execute_reply.started":"2024-04-07T03:31:24.440947Z","shell.execute_reply":"2024-04-07T03:31:24.445393Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"model, optimizer, train_loader, scheduler = accelerator.prepare(\n    model, optimizer, train_loader, scheduler\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:31:47.246699Z","iopub.execute_input":"2024-04-07T03:31:47.247518Z","iopub.status.idle":"2024-04-07T03:31:47.262727Z","shell.execute_reply.started":"2024-04-07T03:31:47.247473Z","shell.execute_reply":"2024-04-07T03:31:47.261798Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(9):\n    for batch in train_loader:\n        input_ids, attention_mask, gender_labels, age_labels = batch\n        \n        with accelerator.autocast():\n            gender_output, age_output = model(input_ids, attention_mask)\n        \n        gender_labels = gender_labels.unsqueeze(1)\n        age_labels = age_labels.unsqueeze(1)\n        \n        gender_loss = gender_criterion(gender_output, gender_labels)\n        age_loss = age_criterion(age_output, age_labels)\n        \n        loss = gender_loss + age_loss\n        accelerator.backward(loss)\n        \n        optimizer.step()\n        optimizer.zero_grad()\n\n    # Print the losses\n    print(f\"Epoch [{epoch+1}/{16}], Gender Loss: {gender_loss.item()}, Age Loss: {age_loss.item()}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T03:31:48.853800Z","iopub.execute_input":"2024-04-07T03:31:48.854907Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/16], Gender Loss: 0.6946000456809998, Age Loss: 589.0359497070312\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-06T20:46:08.150401Z","iopub.execute_input":"2024-04-06T20:46:08.15079Z","iopub.status.idle":"2024-04-06T20:46:08.779479Z","shell.execute_reply.started":"2024-04-06T20:46:08.150763Z","shell.execute_reply":"2024-04-06T20:46:08.778466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}